{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Recommender Systems - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice creating a recommender system model using `surprise`. You'll also get the chance to create a more complete recommender system pipeline to obtain the top recommendations for a specific user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this lab you will: \n",
    "\n",
    "- Use surprise's built-in reader class to process data to work with recommender algorithms \n",
    "- Obtain a prediction for a specific user for a particular item \n",
    "- Introduce a new user with rating to a rating matrix and make recommendations for them \n",
    "- Create a function that will return the top n recommendations for a user \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the famous 1M movie dataset. It contains a collection of user ratings for many different movies. In the last lesson, you were exposed to working with `surprise` datasets. In this lab, you will also go through the process of reading in a dataset into the `surprise` dataset format. To begin with, load the dataset into a Pandas DataFrame. Determine which columns are necessary for your recommendation system and drop any extraneous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating\n",
       "0            1        1     4.0\n",
       "1            1        3     4.0\n",
       "2            1        6     4.0\n",
       "3            1       47     5.0\n",
       "4            1       50     5.0\n",
       "...        ...      ...     ...\n",
       "100831     610   166534     4.0\n",
       "100832     610   168248     5.0\n",
       "100833     610   168250     5.0\n",
       "100834     610   168252     5.0\n",
       "100835     610   170875     3.0\n",
       "\n",
       "[100836 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "new_df = df.drop('timestamp', axis=1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to transform the dataset into something compatible with `surprise`. In order to do this, you're going to need `Reader` and `Dataset` classes. There's a method in `Dataset` specifically for loading dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "# read in values as Surprise dataset \n",
    "\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(new_df,reader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how many users and items we have in our dataset. If using neighborhood-based methods, this will help us determine whether or not we should perform user-user or item-item similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  610 \n",
      "\n",
      "Number of items:  9724\n"
     ]
    }
   ],
   "source": [
    "dataset = data.build_full_trainset()\n",
    "print('Number of users: ', dataset.n_users, '\\n')\n",
    "print('Number of items: ', dataset.n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the best model \n",
    "\n",
    "Now, compare the different models and see which ones perform best. For consistency sake, use RMSE to evaluate models. Remember to cross-validate! Can you get a model with a higher average RMSE on test data than 0.869?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevant libraries\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms import SVD\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8578164176433644, 'mae': 0.6577504248120454}\n",
      "{'rmse': {'n_factors': 100, 'reg_all': 0.05, 'lr_all': 0.01, 'n_epochs': 20}, 'mae': {'n_factors': 100, 'reg_all': 0.05, 'lr_all': 0.01, 'n_epochs': 20}}\n"
     ]
    }
   ],
   "source": [
    "## Perform a gridsearch with SVD\n",
    "# ⏰ This cell may take several minutes to run\n",
    "params = {'n_factors': [25, 50, 100],\n",
    "         'reg_all': [0.025, 0.05, 0.1],\n",
    "         'lr_all': [0.0025, 0.005, 0.01],\n",
    "         'n_epochs': [10, 20]}\n",
    "\n",
    "grid_SVD = GridSearchCV(SVD,param_grid=params,n_jobs=-1)\n",
    "grid_SVD.fit(data)\n",
    "print(grid_SVD.best_score)\n",
    "print(grid_SVD.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8689250510051669, 'mae': 0.6679404366294037}\n",
      "{'rmse': {'n_factors': 50, 'reg_all': 0.05}, 'mae': {'n_factors': 100, 'reg_all': 0.05}}\n"
     ]
    }
   ],
   "source": [
    "# print out optimal parameters for SVD after GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.9466127087281601, 'mae': 0.7255170545933074}\n",
      "{'rmse': {'name': 'cosine', 'user_based': False}, 'mae': {'name': 'cosine', 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "# cross validating with KNNBasic\n",
    "params_KNNBasic = {'name':['cosine','pearson','MSD'], 'user_based':[False]}\n",
    "\n",
    "grid_KNNBasic = GridSearchCV(KNNBasic, param_grid=params_KNNBasic, n_jobs=-1)\n",
    "grid_KNNBasic.fit(data)\n",
    "print(grid_KNNBasic.best_score)\n",
    "print(grid_KNNBasic.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.97267164, 0.96483807, 0.97256294, 0.97971635, 0.97044992]))\n",
      "('test_mae', array([0.74945913, 0.74645346, 0.75109662, 0.75776586, 0.7489072 ]))\n",
      "('fit_time', (1.114384651184082, 1.064413070678711, 1.0618948936462402, 1.0588951110839844, 1.0139226913452148))\n",
      "('test_time', (1.8807368278503418, 1.8927302360534668, 1.8167734146118164, 1.924710988998413, 1.8817367553710938))\n",
      "-----------------------\n",
      "0.9720477864302935\n"
     ]
    }
   ],
   "source": [
    "#ALTERNATE METHOD -- IN SOLUTION NOTEBOOK\n",
    "knn_basic = KNNBasic(sim_options={'name':'pearson', 'user_based':True})\n",
    "cv_knn_basic = cross_validate(knn_basic, data, n_jobs=-1)\n",
    "\n",
    "for i in cv_knn_basic.items():\n",
    "    print(i)\n",
    "print('-----------------------')\n",
    "print(np.mean(cv_knn_basic['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.97646619, 0.97270627, 0.97874535, 0.97029184, 0.96776748]))\n",
      "('test_mae', array([0.75444119, 0.75251222, 0.7531242 , 0.74938542, 0.75152129]))\n",
      "('fit_time', (0.46678805351257324, 0.54010009765625, 0.7059998512268066, 0.5852491855621338, 1.0139541625976562))\n",
      "('test_time', (2.308177947998047, 2.4834508895874023, 2.6563329696655273, 2.652374029159546, 1.2219891548156738))\n",
      "-----------------------\n",
      "0.9731954260849399\n"
     ]
    }
   ],
   "source": [
    "# print out the average RMSE score for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8729968597840161, 'mae': 0.6676178407460321}\n",
      "{'rmse': {'name': 'cosine', 'user_based': False}, 'mae': {'name': 'cosine', 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "# cross validating with KNNBaseline\n",
    "params_KNNBaseline = {'name':['cosine','pearson','MSD'], 'user_based':[False]}\n",
    "\n",
    "grid_KNNBaseline = GridSearchCV(KNNBaseline, param_grid=params_KNNBaseline, n_jobs=-1)\n",
    "grid_KNNBaseline.fit(data)\n",
    "print(grid_KNNBaseline.best_score)\n",
    "print(grid_KNNBaseline.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8729968597840161, 'mae': 0.6676178407460321}\n"
     ]
    }
   ],
   "source": [
    "# print out the average score for the test set\n",
    "print(grid_KNNBaseline.best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based off these outputs, it seems like the best performing model is the SVD model with `n_factors = 50` and a regularization rate of 0.05. Use that model or if you found one that performs better, feel free to use that to make some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8706\n",
      "0.8706331468993987\n"
     ]
    }
   ],
   "source": [
    "## CAH added section\n",
    "\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "svd = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.05)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "svd.fit(trainset)\n",
    "predictions = svd.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='20', iid='10', r_ui=None, est=3.4996962860118015, details={'was_impossible': False})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_20_prediction = svd.predict(\"20\",\"10\")\n",
    "user_20_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Recommendations\n",
    "\n",
    "It's important that the output for the recommendation is interpretable to people. Rather than returning the `movie_id` values, it would be far more valuable to return the actual title of the movie. As a first step, let's read in the movies to a dataframe and take a peek at what information we have about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv('./ml-latest-small/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making simple predictions\n",
    "Just as a reminder, let's look at how you make a prediction for an individual user and item. First, we'll fit the SVD model we had from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x26f30f9b490>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD(n_factors= 50, reg_all=0.05)\n",
    "svd.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=2, iid=4, r_ui=None, est=3.0500290830093, details={'was_impossible': False})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.predict(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0500290830093"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.predict(2,4)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction value is a tuple and each of the values within it can be accessed by way of indexing. Now let's put our knowledge of recommendation systems to do something interesting: making predictions for a new user!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining User Ratings \n",
    "\n",
    "It's great that we have working models and everything, but wouldn't it be nice to get to recommendations specifically tailored to your preferences? That's what we'll be doing now. The first step is to create a function that allows us to pick randomly selected movies. The function should present users with a movie and ask them to rate it. If they have not seen the movie, they should be able to skip rating it. \n",
    "\n",
    "The function `movie_rater()` should take as parameters: \n",
    "\n",
    "* `movie_df`: DataFrame - a dataframe containing the movie ids, name of movie, and genres\n",
    "* `num`: int - number of ratings\n",
    "* `genre`: string - a specific genre from which to draw movies\n",
    "\n",
    "The function returns:\n",
    "* rating_list : list - a collection of dictionaries in the format of {'userId': int , 'movieId': int , 'rating': float}\n",
    "\n",
    "#### This function is optional, but fun :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_rater(movie_df,num, genre=None):\n",
    "    userID = 1000\n",
    "    rating_list = []\n",
    "    while num > 0:\n",
    "        if genre:\n",
    "            movie = movie_df[movie_df['genres'].str.contains(genre)].sample(1)\n",
    "        else:\n",
    "            movie = movie_df.sample(1)\n",
    "        print(movie)\n",
    "        rating = input('How do you rate this movie on a scale of 1-5, press n if you have not seen :\\n')\n",
    "        if rating == 'n':\n",
    "            continue\n",
    "        else:\n",
    "            rating_one_movie = {'userId':userID,'movieId':movie['movieId'].values[0],'rating':rating}\n",
    "            rating_list.append(rating_one_movie) \n",
    "            num -= 1\n",
    "    return rating_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      movieId                                   title  genres\n",
      "8754   128097  Jim Norton: American Degenerate (2013)  Comedy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId                    title                genres\n",
      "3878     5450  Lovely & Amazing (2001)  Comedy|Drama|Romance\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "1\n",
      "      movieId                       title  genres\n",
      "5897    33495  Kicking & Screaming (2005)  Comedy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "3\n",
      "      movieId                                           title  \\\n",
      "8422   111146  Alpha and Omega 3: The Great Wolf Games (2014)   \n",
      "\n",
      "                                          genres  \n",
      "8422  Action|Adventure|Animation|Children|Comedy  \n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId                  title          genres\n",
      "6689    58162  Run Fatboy Run (2007)  Comedy|Romance\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "1\n",
      "      movieId                     title                   genres\n",
      "9238   153386  Long Live Ghosts! (1977)  Children|Comedy|Fantasy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId             title          genres\n",
      "4717     7036  Teen Wolf (1985)  Comedy|Fantasy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "5\n",
      "      movieId            title  genres\n",
      "8724   126548  The DUFF (2015)  Comedy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'userId': 1000, 'movieId': 5450, 'rating': '1'},\n",
       " {'userId': 1000, 'movieId': 33495, 'rating': '3'},\n",
       " {'userId': 1000, 'movieId': 58162, 'rating': '1'},\n",
       " {'userId': 1000, 'movieId': 7036, 'rating': '5'},\n",
       " {'userId': 1000, 'movieId': 126548, 'rating': '4'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ratings = movie_rater(df_movies, 5, genre='Comedy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      movieId                   title          genres\n",
      "6579    55245  Good Luck Chuck (2007)  Comedy|Romance\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "5\n",
      "      movieId                       title          genres\n",
      "1873     2491  Simply Irresistible (1999)  Comedy|Romance\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "4\n",
      "      movieId                  title  genres\n",
      "3459     4718  American Pie 2 (2001)  Comedy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "4\n",
      "      movieId             title                   genres\n",
      "4160     5990  Pinocchio (2002)  Children|Comedy|Fantasy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# try out the new function here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're struggling to come up with the above function, you can use this list of user ratings to complete the next segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'userId': 1000, 'movieId': 55245, 'rating': '5'},\n",
       " {'userId': 1000, 'movieId': 2491, 'rating': '4'},\n",
       " {'userId': 1000, 'movieId': 4718, 'rating': '4'},\n",
       " {'userId': 1000, 'movieId': 5990, 'rating': '3'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rating = [{'userId': 1000, 'movieId': 55245, 'rating': '5'},\n",
    " {'userId': 1000, 'movieId': 2491, 'rating': '4'},\n",
    " {'userId': 1000, 'movieId': 4718, 'rating': '4'},\n",
    " {'userId': 1000, 'movieId': 5990, 'rating': '3'}]\n",
    "user_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions With the New Ratings\n",
    "Now that you have new ratings, you can use them to make predictions for this new user. The proper way this should work is:\n",
    "\n",
    "* add the new ratings to the original ratings DataFrame, read into a `surprise` dataset \n",
    "* train a model using the new combined DataFrame\n",
    "* make predictions for the user\n",
    "* order those predictions from highest rated to lowest rated\n",
    "* return the top n recommendations with the text of the actual movie (rather than just the index number) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add the new ratings to the original ratings DataFrame\n",
    "user_ratings = pd.DataFrame(user_rating)\n",
    "new_ratings_df = pd.concat([new_df, user_ratings], axis=0)\n",
    "new_data = Dataset.load_from_df(new_ratings_df,reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x26f3117ebe0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a model using the new combined DataFrame\n",
    "svd = SVD(n_factors= 50, reg_all=0.05)\n",
    "svd.fit(new_data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for the user\n",
    "# you'll probably want to create a list of tuples in the format (movie_id, predicted_score)\n",
    "list_of_movies = []\n",
    "for movieID in new_df['movieId'].unique():\n",
    "    list_of_movies.append( (movieID, svd.predict(1000, movieID)[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1213, 4.540303894047375),\n",
       " (1262, 4.5346802467618605),\n",
       " (1104, 4.530946934575698),\n",
       " (1204, 4.513987416519957),\n",
       " (1089, 4.504985832716824),\n",
       " (318, 4.498675050896076),\n",
       " (898, 4.491830769009865),\n",
       " (904, 4.490977313549253),\n",
       " (858, 4.48939152742239),\n",
       " (750, 4.479613633459128)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order the predictions from highest to lowest rated\n",
    "\n",
    "ranked_movies = sorted(list_of_movies, key=lambda x:x[1], reverse=True)\n",
    "ranked_movies[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For the final component of this challenge, it could be useful to create a function `recommended_movies()` that takes in the parameters:\n",
    "* `user_ratings`: list - list of tuples formulated as (user_id, movie_id) (should be in order of best to worst for this individual)\n",
    "* `movie_title_df`: DataFrame \n",
    "* `n`: int - number of recommended movies \n",
    "\n",
    "The function should use a `for` loop to print out each recommended *n* movies in order from best to worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation #  1 :  914    Goodfellas (1990)\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation #  2 :  961    Great Escape, The (1963)\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation #  3 :  841    Streetcar Named Desire, A (1951)\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation #  4 :  906    Lawrence of Arabia (1962)\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation #  5 :  828    Reservoir Dogs (1992)\n",
      "Name: title, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# return the top n recommendations using the \n",
    "def recommended_movies(user_ratings,movie_title_df,n):\n",
    "        for idx, rec in enumerate(user_ratings):\n",
    "            title = movie_title_df.loc[movie_title_df['movieId'] == int(rec[0])]['title']\n",
    "            print('Recommendation # ', idx+1, ': ', title, '\\n')\n",
    "            n-= 1\n",
    "            if n == 0:\n",
    "                break\n",
    "            \n",
    "recommended_movies(ranked_movies,df_movies,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up (Optional)\n",
    "\n",
    "* Try and chain all of the steps together into one function that asks users for ratings for a certain number of movies, then all of the above steps are performed to return the top $n$ recommendations\n",
    "* Make a recommender system that only returns items that come from a specified genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_from_ratings(movie_df, n_ratings, n_recs):\n",
    "    \n",
    "    ratinglist = movie_rater(movie_df, n_ratings, genre=None)\n",
    "    \n",
    "    user_ratings = pd.DataFrame(ratinglist)\n",
    "    new_ratings_df = pd.concat([movie_df, user_ratings], axis=0)\n",
    "    new_data = Dataset.load_from_df(new_ratings_df,reader)\n",
    "    \n",
    "    svd = SVD(n_factors= 50, reg_all=0.05)\n",
    "    svd.fit(new_data.build_full_trainset())\n",
    "    \n",
    "    list_of_movies = []\n",
    "    for movieID in new_df['movieId'].unique():\n",
    "        list_of_movies.append( (movieID, svd.predict(1000, movieID)[3]))\n",
    "    ranked_movies = sorted(list_of_movies, key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    recommended_movies(ranked_movies, movie_df, n_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      movieId                   title                   genres\n",
      "1369     1873  Misérables, Les (1998)  Crime|Drama|Romance|War\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "5\n",
      "      movieId                                   title         genres\n",
      "8267   105246  Mood Indigo (L'écume des jours) (2013)  Drama|Fantasy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "2\n",
      "      movieId             title           genres\n",
      "1839     2446  In Dreams (1999)  Horror|Thriller\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "4\n",
      "      movieId            title                  genres\n",
      "1373     1882  Godzilla (1998)  Action|Sci-Fi|Thriller\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "1\n",
      "      movieId                           title              genres\n",
      "1525     2057  Incredible Journey, The (1963)  Adventure|Children\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "5\n",
      "      movieId                               title                      genres\n",
      "8627   118894  Scooby-Doo! Abracadabra-Doo (2010)  Animation|Children|Mystery\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "1\n",
      "      movieId                                 title          genres\n",
      "4852     7255  Win a Date with Tad Hamilton! (2004)  Comedy|Romance\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "1\n",
      "      movieId                            title  \\\n",
      "7411    80363  Resident Evil: Afterlife (2010)   \n",
      "\n",
      "                                  genres  \n",
      "7411  Action|Horror|Sci-Fi|Thriller|IMAX  \n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "1\n",
      "      movieId               title                             genres\n",
      "2768     3706  Angel Heart (1987)  Film-Noir|Horror|Mystery|Thriller\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "2\n",
      "      movieId               title           genres\n",
      "2987     4000  Bounty, The (1984)  Adventure|Drama\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-d68b445751ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_recommendations_from_ratings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_movies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-1869b6eb3d4a>\u001b[0m in \u001b[0;36mget_recommendations_from_ratings\u001b[1;34m(movie_df, n_ratings, n_recs)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0muser_ratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratinglist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnew_ratings_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmovie_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_ratings\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_ratings_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msvd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_factors\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\surprise\\dataset.py\u001b[0m in \u001b[0;36mload_from_df\u001b[1;34m(cls, df, reader)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \"\"\"\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDatasetAutoFolds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_ratings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\surprise\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, ratings_file, reader, df)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             self.raw_ratings = [(uid, iid, float(r), None)\n\u001b[0m\u001b[0;32m    257\u001b[0m                                 \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m                                 self.df.itertuples(index=False)]\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\surprise\\dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             self.raw_ratings = [(uid, iid, float(r), None)\n\u001b[0m\u001b[0;32m    257\u001b[0m                                 \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m                                 self.df.itertuples(index=False)]\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "get_recommendations_from_ratings(df_movies, 10, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you got the chance to implement a collaborative filtering model as well as retrieve recommendations from that model. You also got the opportunity to add your own recommendations to the system to get new recommendations for yourself! Next, you will learn how to use Spark to make recommender systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
